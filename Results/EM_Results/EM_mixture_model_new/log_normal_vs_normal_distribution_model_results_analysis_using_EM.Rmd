---
title: "Comparing log normal to normal distribution models"
author: "Nitay Alon"
date: "10/31/2018"
output: html_document
---

In this report we'll compare and analyze the difference between the normal and log-normal model for gender mixture data over brain features. The main goal is to test the mixture model hypothesis, described in the next section. In addition we examine the goodness of fit to decide which of the models fits the data better in terms of log-likelihood. We present the results of applying EM for MLE computation for each feature and analysis of the method and the results is presented.

## The data and hypothesis
In this paper we analyze the brain features of 1570 people, belonging to 2 groups - men and women. In this report we've analyzed 3 data files: GSP FS volume and measures and GSP VMB.
The data quality process included removal of missing data, validation of positivity (measure cannot be negative) and labeling the subject sex.In addition we've applied scaling on the data (standardization).
We assume that the measurements of brain features are sampled from distribution $f_X(x)$. We assume that each person in the data sample the measurement of its feature from one of 
two distributions: $f_1(x), f_2(x)$. 
The model in question is a mixture model, *that is*, we assume that the men and women brain data is a mixture of two distributions and not a pure distribution (pure type model).To test this hypothesis we use log-likelihood ratio test (llrt). 

## EM algorithm for mixture of two populations and two samples 
Under the alternative hypothesis we assume that the gender data is a mixture of two sex mixture. To estimate the MLE under this hypothesis we used the EM algorithm (Dempster,Laired,Rubin 1977). 

The alternative model assumes the following:

1. Each gender measures is a mixture model of the sex distribution:
\[
f_X(x) = pf_1(x) + (1-p)f_2(x)
\]
2. The underline distributions are normal with means $\theta_1,\theta_2$ such that $\theta_1 < 0 < \theta_2$
3. We assume equal variance between the groups
The EM equations are listed in the appendix. 
The null hypothesis assumes a 'pure type' model, that is:

1. Each gender measures is generated from a single distribution:
\[
f_X(x) = f_i(x)
\]
2. The underline distributions are normal with mean $\theta_i$ 
3. We assume equal variance between the groups

The MLE's under the null hypothesis are the usual MLE for normal data.

## Analysis and discussion
In this section we discuss the findings form the EM and llrt and compare the normal vs log normal assumption.

### GSP_FS_thickness+sex+age
We begin with the first GSP file. The algorithm was applied as described above and the results of both log-normal and normal model are presented bellow.
```{r applying_EM_over_GSP_FS_thickness+sex+age,echo=FALSE}
config <- config::get(file = "~/mastersdegree/Thesis/DAPHNA_JOEL/config.yml")
load("~/mastersdegree/Thesis/DAPHNA_JOEL/Mixture_models/Log_normal_mixture_model/EM_Results/GSP_FS_thickness+sex+age")
llrt_results_list <- sapply(grid_search_results$llr_per_feature, function(x)unlist(x))
llrt_results_df <- as.data.frame(llrt_results_list[,-1])
llrt_results_df <- as.data.frame(t(llrt_results_df))
rownames(llrt_results_df) <- NULL
colnames(llrt_results_df) <- c("Feature","Log_noraml","Normal")
llrt_results_df$Log_noraml <- as.numeric(levels(llrt_results_df$Log_noraml))[llrt_results_df$Log_noraml]
llrt_results_df$Feature <- as.character(levels(llrt_results_df$Feature))[llrt_results_df$Feature]
llrt_results_df$Normal <- as.numeric(levels(llrt_results_df$Normal))[llrt_results_df$Normal]
```

```{r analysis_of_GSP_FS_thickness+sex+age}
library(ggplot2)
library(gridExtra)
llrt_per_feature <- ggplot(llrt_results_df, aes(Feature)) + 
  geom_point(aes(y = Log_noraml, colour = "Log_noraml")) + 
  geom_point(aes(y = Normal, colour = "Normal")) 
llrt_per_feature + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
  ggtitle("Log-likelihood ratio", subtitle = "GSP_FS_thickness+sex+age") + geom_hline(yintercept=qexp(0.99,2), linetype="dashed", color = "red") + ylab("log-likelihood ratio")
```

The dashed red line marks the $99$ quantile of $exp(2)$ distribution, corresponding to the asymptotic distribution of the log likelihood ratio (Wilks' theorem) and the proper rejecting region under FDR.
The first noticeable fact is that there's more discoveries under the normal distribution assumption than the log normal assumption, this worth further inquiry.

#### Handling identifabily issue
Let's focus on the features with the lowest llrt.
```{r load_low_llrt_filter, echo=FALSE}
feature_name <- llrt_results_df$Feature[which.min(llrt_results_df$Normal)]
load("~/mastersdegree/Thesis/DAPHNA_JOEL/Mixture_models/Log_normal_mixture_model/EM_Results/GSP_FS_thickness+sex+ageBrain_file_class_")
source("~/mastersdegree/Thesis/DAPHNA_JOEL/Data/brain_data_class/source_brain_feature_class.R")
source("~/mastersdegree/Thesis/DAPHNA_JOEL/Data/brain_data_class/source_brain_file_class.R")
brain_feature <- new("brainFeatureData")
brain_feature <- loadBrainFeatureData(brain_feature,
                                          brain_file_data_with_data,
                                          feature_name)
brain_feature_log <- applyLogTransformationOnBrainFeatureData(brain_feature)
brain_feature_scaled <- applyScalingOnBrainFeatureData(brain_feature_log)
```
if we plot a histogram of this feature:
```{r plot_feature_with_low_llrt}
raw_data_plot <- plotBrainFeature(brain_feature_scaled,F)
raw_data_plot
```

And the scaled data histogram:
```{r scaled low llrt feature histogram}
raw_data_plot <- plotBrainFeature(brain_feature_scaled,T)
raw_data_plot
```

Looking at the plots, there's a reason to believe that the mixture model hypothesis is more likely than the null hypothesis. The last claim can be justified by observing that some observations are relatively far from the center mass. We'll re-run the EM algorithm on this feature and analyze the results.
```{r apply EM on the low llrt feature ,echo=FALSE}
source("~/mastersdegree/Thesis/DAPHNA_JOEL/Mixture_models/EM/source_file_EM.R")
source("~/mastersdegree/Thesis/DAPHNA_JOEL/Mixture_models/source_script.R")
em_log_normal <- createEMClassForFeature(feature_name, T, brain_feature_scaled@scaled_log_value)

men <- em_log_normal@data_file$value[em_log_normal@data_file$bio_sex == 1]
women <- em_log_normal@data_file$value[em_log_normal@data_file$bio_sex == 2]
men_mean <- mean(men)
women_mean <- mean(women)
null_var <- computePooledVariance(men,women)

null_plot <- ggplot(em_log_normal@data_file, aes(value, fill = bio_sex)) + 
  geom_histogram(bins = 70, aes(y = (..density..))) + 
  stat_function(fun = dnorm, colour = "red", args = list(mean = men_mean, sd = sqrt(null_var))) +
  stat_function(fun = dnorm, colour = "blue", args = list(mean = women_mean, sd = sqrt(null_var))) + ggtitle("Null hypothesis plot")
 

mas_mean = em_log_normal@EM_results$EM_results$m_parameters$mu_1
fem_mean = em_log_normal@EM_results$EM_results$m_parameters$mu_2
alt_var = em_log_normal@EM_results$EM_results$m_parameters$sigma_2

alternative_plot <- ggplot(em_log_normal@data_file, aes(value, fill = bio_sex)) + 
  geom_histogram(bins = 70, aes(y = (..density..))) + 
  stat_function(fun = dnorm, colour = "red", args = list(mean = mas_mean, sd = sqrt(alt_var))) + 
  stat_function(fun = dnorm, colour = "blue", args = list(mean = fem_mean, sd = sqrt(alt_var))) + ggtitle("Alternative hypothesis plot")

grid.arrange(null_plot,alternative_plot, ncol = 2, nrow = 1)
```
here we can see that we get two different distributions with the same likelihood, which might indicate a label switching problem. To test this problem, let's apply the EM again but with more iterations.
```{r apply EM on the low llrt feature more iterations}
em_log_normal <- createEMClassForFeature(feature_name, T, brain_feature_scaled@scaled_log_value)

men <- em_log_normal@data_file$value[em_log_normal@data_file$bio_sex == 1]
women <- em_log_normal@data_file$value[em_log_normal@data_file$bio_sex == 2]
men_mean <- mean(men)
women_mean <- mean(women)
null_var <- computePooledVariance(men,women)

null_plot <- ggplot(em_log_normal@data_file, aes(value, fill = bio_sex)) + 
  geom_histogram(bins = 70, aes(y = (..density..))) + 
  stat_function(fun = dnorm, colour = "red", args = list(mean = men_mean, sd = sqrt(null_var))) +
  stat_function(fun = dnorm, colour = "blue", args = list(mean = women_mean, sd = sqrt(null_var))) + ggtitle("Null hypothesis plot")
 

mas_mean = em_log_normal@EM_results$EM_results$m_parameters$mu_1
fem_mean = em_log_normal@EM_results$EM_results$m_parameters$mu_2
alt_var = em_log_normal@EM_results$EM_results$m_parameters$sigma_2

alternative_plot <- ggplot(em_log_normal@data_file, aes(value, fill = bio_sex)) + 
  geom_histogram(bins = 70, aes(y = (..density..))) + 
  stat_function(fun = dnorm, colour = "red", args = list(mean = mas_mean, sd = sqrt(alt_var))) + 
  stat_function(fun = dnorm, colour = "blue", args = list(mean = fem_mean, sd = sqrt(alt_var))) + ggtitle("Alternative hypothesis plot")

grid.arrange(null_plot,alternative_plot, ncol = 2, nrow = 1)
```
And the results are practically the same, leading us to believe that there's indeed ineffability issue in this feature. It is possible that in other features with low llrt and small disagreement between the normal and log normal models the situation is the same.

#### Exploring disagreements between the models
Next we explore features with high disagreement between the normal and log normal model. To do so let's select the features with the highest "conflict" between the models. 
```{r select features with hight disagreement}
llrt_results_df$diff <- llrt_results_df$Log_noraml - llrt_results_df$Normal
normal_feature <- llrt_results_df$Feature[which.min(llrt_results_df$diff)]
log_normal_feature <- llrt_results_df$Feature[which.max(llrt_results_df$diff)]
```
Apply EM on the normal favored feature
```{r apply EM on noraml favored data - normal}
normal_brain_feature <- loadBrainFeatureData(brain_feature,
                                          brain_file_data_with_data,
                                          normal_feature)
normal_brain_feature_log <- applyLogTransformationOnBrainFeatureData(normal_brain_feature)
normal_brain_feature_scaled <- applyScalingOnBrainFeatureData(normal_brain_feature_log)

em_normal <- createEMClassForFeature(normal_feature, F, normal_brain_feature_scaled@scaled_value)

men <- em_normal@data_file$value[em_log_normal@data_file$bio_sex == 1]
women <- em_normal@data_file$value[em_log_normal@data_file$bio_sex == 2]
men_mean <- mean(men)
women_mean <- mean(women)
null_var <- computePooledVariance(men,women)

null_plot <- ggplot(em_normal@data_file, aes(value, fill = bio_sex)) + 
  geom_histogram(bins = 70, aes(y = (..density..))) + 
  stat_function(fun = dnorm, colour = "red", args = list(mean = men_mean, sd = sqrt(null_var))) +
  stat_function(fun = dnorm, colour = "blue", args = list(mean = women_mean, sd = sqrt(null_var))) + ggtitle("Null hypothesis plot")
 

mas_mean = em_normal@EM_results$EM_results$m_parameters$mu_1
fem_mean = em_normal@EM_results$EM_results$m_parameters$mu_2
alt_var = em_normal@EM_results$EM_results$m_parameters$sigma_2

alternative_plot <- ggplot(em_normal@data_file, aes(value, fill = bio_sex)) + 
  geom_histogram(bins = 70, aes(y = (..density..))) + 
  stat_function(fun = dnorm, colour = "red", args = list(mean = mas_mean, sd = sqrt(alt_var))) + 
  stat_function(fun = dnorm, colour = "blue", args = list(mean = fem_mean, sd = sqrt(alt_var))) + ggtitle("Alternative hypothesis plot")

grid.arrange(null_plot,alternative_plot, ncol = 2, nrow = 1)
```

And compare the results to the same data but with log normal assumption:
```{r apply EM on noraml favored data - log normal}
em_log_normal <- createEMClassForFeature(normal_feature, T, normal_brain_feature_scaled@scaled_log_value)

men <- em_log_normal@data_file$value[em_log_normal@data_file$bio_sex == 1]
women <- em_log_normal@data_file$value[em_log_normal@data_file$bio_sex == 2]
men_mean <- mean(men)
women_mean <- mean(women)
null_var <- computePooledVariance(men,women)

null_plot <- ggplot(em_log_normal@data_file, aes(value, fill = bio_sex)) + 
  geom_histogram(bins = 70, aes(y = (..density..))) + 
  stat_function(fun = dnorm, colour = "red", args = list(mean = men_mean, sd = sqrt(null_var))) +
  stat_function(fun = dnorm, colour = "blue", args = list(mean = women_mean, sd = sqrt(null_var))) + ggtitle("Null hypothesis plot")
 

mas_mean = em_log_normal@EM_results$EM_results$m_parameters$mu_1
fem_mean = em_log_normal@EM_results$EM_results$m_parameters$mu_2
alt_var = em_log_normal@EM_results$EM_results$m_parameters$sigma_2

alternative_plot <- ggplot(em_log_normal@data_file, aes(value, fill = bio_sex)) + 
  geom_histogram(bins = 70, aes(y = (..density..))) + 
  stat_function(fun = dnorm, colour = "red", args = list(mean = mas_mean, sd = sqrt(alt_var))) + 
  stat_function(fun = dnorm, colour = "blue", args = list(mean = fem_mean, sd = sqrt(alt_var))) + ggtitle("Alternative hypothesis plot")

grid.arrange(null_plot,alternative_plot, ncol = 2, nrow = 1)
```

And we can see that the results are very similar, up to small changes in the MLE of the alternative model.
Next let's look at a feature with high llrt under the log-normal model:
```{r apply EM on noraml favored data - log normal 2}
log_normal_brain_feature <- loadBrainFeatureData(brain_feature,
                                          brain_file_data_with_data,
                                          log_normal_feature)
log_normal_brain_feature_log <- applyLogTransformationOnBrainFeatureData(log_normal_brain_feature)
log_normal_brain_feature_scaled <- applyScalingOnBrainFeatureData(log_normal_brain_feature_log)

em_normal <- createEMClassForFeature(normal_feature, F, log_normal_brain_feature_scaled@scaled_value)

men <- em_normal@data_file$value[em_log_normal@data_file$bio_sex == 1]
women <- em_normal@data_file$value[em_log_normal@data_file$bio_sex == 2]
men_mean <- mean(men)
women_mean <- mean(women)
null_var <- computePooledVariance(men,women)

null_plot <- ggplot(em_normal@data_file, aes(value, fill = bio_sex)) + 
  geom_histogram(bins = 70, aes(y = (..density..))) + 
  stat_function(fun = dnorm, colour = "red", args = list(mean = men_mean, sd = sqrt(null_var))) +
  stat_function(fun = dnorm, colour = "blue", args = list(mean = women_mean, sd = sqrt(null_var))) + ggtitle("Null hypothesis plot")
 

mas_mean = em_normal@EM_results$EM_results$m_parameters$mu_1
fem_mean = em_normal@EM_results$EM_results$m_parameters$mu_2
alt_var = em_normal@EM_results$EM_results$m_parameters$sigma_2

alternative_plot <- ggplot(em_normal@data_file, aes(value, fill = bio_sex)) + 
  geom_histogram(bins = 70, aes(y = (..density..))) + 
  stat_function(fun = dnorm, colour = "red", args = list(mean = mas_mean, sd = sqrt(alt_var))) + 
  stat_function(fun = dnorm, colour = "blue", args = list(mean = fem_mean, sd = sqrt(alt_var))) + ggtitle("Alternative hypothesis plot")

grid.arrange(null_plot,alternative_plot, ncol = 2, nrow = 1)
```

Here we can see that the distribution match the type of distributions "classified" as good candidates for discovery using the KLD partition.

#### Summary GSP_FS_thickness+sex+age

Final we summarize the results of the llrt:
```{r summary table GSP_FS_thickness+sex+age}
library(knitr)
data_for_table <- data.frame(log_normal = nrow(llrt_results_df[llrt_results_df$Log_noraml > qexp(0.99,2),]),
                             normal = nrow(llrt_results_df[llrt_results_df$Normal > qexp(0.99,2),]),
                             number_of_features = nrow(llrt_results_df)
                               )
kable(data_for_table, caption = "log-likelihood ratio test")
```

### GSP_FS_volume_relevant+sex+age

Next we analyze the GSP FS volume file. 
```{r, echo=FALSE}
load("~/mastersdegree/Thesis/DAPHNA_JOEL/Mixture_models/Log_normal_mixture_model/EM_Results/GSP_FS_volume_relevant+sex+age")
llrt_results_list <- sapply(grid_search_results$llr_per_feature, function(x)unlist(x))
llrt_results_df <- as.data.frame(llrt_results_list[,-1])
llrt_results_df <- as.data.frame(t(llrt_results_df))
rownames(llrt_results_df) <- NULL
colnames(llrt_results_df) <- c("Feature","Log_noraml","Normal")
llrt_results_df$Log_noraml <- as.numeric(levels(llrt_results_df$Log_noraml))[llrt_results_df$Log_noraml]
llrt_results_df$Feature <- as.character(levels(llrt_results_df$Feature))[llrt_results_df$Feature]
llrt_results_df$Normal <- as.numeric(levels(llrt_results_df$Normal))[llrt_results_df$Normal]
```

Plotting the results:
```{r}
llrt_per_feature <- ggplot(llrt_results_df, aes(Feature)) + 
  geom_point(aes(y = Log_noraml, colour = "Log_noraml")) + 
  geom_point(aes(y = Normal, colour = "Normal")) 
llrt_per_feature + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
  ggtitle("Log-likelihood ratio", subtitle = "GSP_FS_thickness+sex+age") + geom_hline(yintercept=qexp(0.99,2), linetype="dashed", color = "red") 
```

Here we see that the normal distribution assumption we get more discoveries. 
```{r adding diff llrt}
llrt_results_df$diff <- llrt_results_df$Log_noraml - llrt_results_df$Normal
```

Examining high llrt features:

```{r high normal llrt feature}
load("~/mastersdegree/Thesis/DAPHNA_JOEL/Mixture_models/Log_normal_mixture_model/EM_Results/GSP_FS_volume_relevant+sex+ageBrain_file_class_")

normal_feature <- llrt_results_df$Feature[which.max(llrt_results_df$Normal)]

brain_feature <- new("brainFeatureData")
brain_feature <- loadBrainFeatureData(brain_feature,
                                          brain_file_data_with_data,
                                          normal_feature)
brain_feature_log <- applyLogTransformationOnBrainFeatureData(brain_feature)
brain_feature_scaled <- applyScalingOnBrainFeatureData(brain_feature_log)


normal_brain_feature <- loadBrainFeatureData(brain_feature,
                                          brain_file_data_with_data,
                                          normal_feature)
normal_brain_feature_log <- applyLogTransformationOnBrainFeatureData(normal_brain_feature)
normal_brain_feature_scaled <- applyScalingOnBrainFeatureData(normal_brain_feature_log)

em_normal <- createEMClassForFeature(normal_feature, F, normal_brain_feature_scaled@scaled_value)

men <- em_normal@data_file$value[em_normal@data_file$bio_sex == 1]
women <- em_normal@data_file$value[em_normal@data_file$bio_sex == 2]
men_mean <- mean(men)
women_mean <- mean(women)
null_var <- computePooledVariance(men,women)

null_plot <- ggplot(em_normal@data_file, aes(value, fill = bio_sex)) + 
  geom_histogram(bins = 70, aes(y = (..density..))) + 
  stat_function(fun = dnorm, colour = "red", args = list(mean = men_mean, sd = sqrt(null_var))) +
  stat_function(fun = dnorm, colour = "blue", args = list(mean = women_mean, sd = sqrt(null_var))) + ggtitle("Null hypothesis plot")
 

mas_mean = em_normal@EM_results$EM_results$m_parameters$mu_1
fem_mean = em_normal@EM_results$EM_results$m_parameters$mu_2
alt_var = em_normal@EM_results$EM_results$m_parameters$sigma_2

alternative_plot <- ggplot(em_normal@data_file, aes(value, fill = bio_sex)) + 
  geom_histogram(bins = 70, aes(y = (..density..))) + 
  stat_function(fun = dnorm, colour = "red", args = list(mean = mas_mean, sd = sqrt(alt_var))) + 
  stat_function(fun = dnorm, colour = "blue", args = list(mean = fem_mean, sd = sqrt(alt_var))) + ggtitle("Alternative hypothesis plot")

grid.arrange(null_plot,alternative_plot, ncol = 2, nrow = 1)
```
Note that in this particular case the distribution follows a log normal shape. We repeat the same process for the second highest llrt:

```{r high normal llrt feature 2}
normal_feature <- "left.lateral.ventricle"
brain_feature <- new("brainFeatureData")
brain_feature <- loadBrainFeatureData(brain_feature,
                                          brain_file_data_with_data,
                                          normal_feature)
brain_feature_log <- applyLogTransformationOnBrainFeatureData(brain_feature)
brain_feature_scaled <- applyScalingOnBrainFeatureData(brain_feature_log)

normal_brain_feature <- loadBrainFeatureData(brain_feature,
                                          brain_file_data_with_data,
                                          normal_feature)
normal_brain_feature_log <- applyLogTransformationOnBrainFeatureData(normal_brain_feature)
normal_brain_feature_scaled <- applyScalingOnBrainFeatureData(normal_brain_feature_log)

em_normal <- createEMClassForFeature(normal_feature, F, normal_brain_feature_scaled@scaled_value)

men <- em_normal@data_file$value[em_normal@data_file$bio_sex == 1]
women <- em_normal@data_file$value[em_normal@data_file$bio_sex == 2]
men_mean <- mean(men)
women_mean <- mean(women)
null_var <- computePooledVariance(men,women)

null_plot <- ggplot(em_normal@data_file, aes(value, fill = bio_sex)) + 
  geom_histogram(bins = 70, aes(y = (..density..))) + 
  stat_function(fun = dnorm, colour = "red", args = list(mean = men_mean, sd = sqrt(null_var))) +
  stat_function(fun = dnorm, colour = "blue", args = list(mean = women_mean, sd = sqrt(null_var))) + ggtitle("Null hypothesis plot")
 

mas_mean = em_normal@EM_results$EM_results$m_parameters$mu_1
fem_mean = em_normal@EM_results$EM_results$m_parameters$mu_2
alt_var = em_normal@EM_results$EM_results$m_parameters$sigma_2

alternative_plot <- ggplot(em_normal@data_file, aes(value, fill = bio_sex)) + 
  geom_histogram(bins = 70, aes(y = (..density..))) + 
  stat_function(fun = dnorm, colour = "red", args = list(mean = mas_mean, sd = sqrt(alt_var))) + 
  stat_function(fun = dnorm, colour = "blue", args = list(mean = fem_mean, sd = sqrt(alt_var))) + ggtitle("Alternative hypothesis plot")

grid.arrange(null_plot,alternative_plot, ncol = 2, nrow = 1)
```

Again, similar distribution shape.

#### Summary

```{r summary table GSP VBM}
data_for_table <- data.frame(log_normal = nrow(llrt_results_df[llrt_results_df$Log_noraml > qexp(0.99,2),]),
                             normal = nrow(llrt_results_df[llrt_results_df$Normal > qexp(0.99,2),]),
                             number_of_features = nrow(llrt_results_df)
                               )
kable(data_for_table, caption = "log-likelihood ratio test")
```

### GPS VBM
Last we repeat the analysis for the GSP VBM data file

```{r load GSP VBM data, echo=FALSE}
load("~/mastersdegree/Thesis/DAPHNA_JOEL/Mixture_models/Log_normal_mixture_model/EM_Results/GSP_VBM_dataBrain_file_class_")
load("~/mastersdegree/Thesis/DAPHNA_JOEL/Mixture_models/Log_normal_mixture_model/EM_Results/GSP_VBM_data")
llrt_results_list <- sapply(grid_search_results$llr_per_feature, function(x)unlist(x))
llrt_results_df <- as.data.frame(llrt_results_list[-1])
llrt_results_df <- as.data.frame(t(llrt_results_df))
rownames(llrt_results_df) <- NULL
colnames(llrt_results_df) <- c("Feature","Log_noraml","Normal")
llrt_results_df$Log_noraml <- as.numeric(levels(llrt_results_df$Log_noraml))[llrt_results_df$Log_noraml]
llrt_results_df$Feature <- as.character(levels(llrt_results_df$Feature))[llrt_results_df$Feature]
llrt_results_df$Normal <- as.numeric(levels(llrt_results_df$Normal))[llrt_results_df$Normal]
```

Plotting the llrt:

```{r plot GSP VMB llrt}
llrt_per_feature <- ggplot(llrt_results_df[-1,], aes(Feature)) + 
  geom_point(aes(y = Log_noraml, colour = "Log_noraml")) + 
  geom_point(aes(y = Normal, colour = "Normal")) 
llrt_per_feature + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
  ggtitle("Log-likelihood ratio", subtitle = "GSP_VMB") + geom_hline(yintercept=qexp(0.99,2), linetype="dashed", color = "red") + ylab("log-likelihood ratio")
```

Here we see an interesting pattern - the log normal model yields higher number of significant features, as presented in following table:

```{r summary table GSP_VBM}
data_for_table <- data.frame(log_normal = nrow(llrt_results_df[llrt_results_df$Log_noraml > qexp(0.99,2),]),
                             normal = nrow(llrt_results_df[llrt_results_df$Normal > qexp(0.99,2),]),
                             number_of_features = nrow(llrt_results_df)
                               )
kable(data_for_table, caption = "log-likelihood ratio test")
```

If we focus our intention to the highest llrt feature:

```{r high normal llrt feature GSP VBM}
log_normal_feature <- llrt_results_df$Feature[which.max(llrt_results_df$Log_noraml)]

brain_feature <- new("brainFeatureData")
brain_feature <- loadBrainFeatureData(brain_feature,
                                          brain_file_data_with_data,
                                          log_normal_feature)
brain_feature_log <- applyLogTransformationOnBrainFeatureData(brain_feature)
brain_feature_scaled <- applyScalingOnBrainFeatureData(brain_feature_log)

log_normal_brain_feature <- loadBrainFeatureData(brain_feature,
                                          brain_file_data_with_data,
                                          log_normal_feature)
log_normal_brain_feature_log <- applyLogTransformationOnBrainFeatureData(log_normal_brain_feature)
log_normal_brain_feature_scaled <- applyScalingOnBrainFeatureData(log_normal_brain_feature_log)

em_log_normal <- createEMClassForFeature(log_normal_feature, F, log_normal_brain_feature_scaled@scaled_value)

men <- em_log_normal@data_file$value[em_log_normal@data_file$bio_sex == 1]
women <- em_log_normal@data_file$value[em_log_normal@data_file$bio_sex == 2]
men_mean <- mean(men)
women_mean <- mean(women)
null_var <- computePooledVariance(men,women)

null_plot <- ggplot(em_log_normal@data_file, aes(value, fill = bio_sex)) + 
  geom_histogram(bins = 70, aes(y = (..density..))) + 
  stat_function(fun = dnorm, colour = "red", args = list(mean = men_mean, sd = sqrt(null_var))) +
  stat_function(fun = dnorm, colour = "blue", args = list(mean = women_mean, sd = sqrt(null_var))) + ggtitle("Null hypothesis plot")
 

mas_mean = em_log_normal@EM_results$EM_results$m_parameters$mu_1
fem_mean = em_log_normal@EM_results$EM_results$m_parameters$mu_2
alt_var = em_log_normal@EM_results$EM_results$m_parameters$sigma_2

alternative_plot <- ggplot(em_log_normal@data_file, aes(value, fill = bio_sex)) + 
  geom_histogram(bins = 70, aes(y = (..density..))) + 
  stat_function(fun = dnorm, colour = "red", args = list(mean = mas_mean, sd = sqrt(alt_var))) + 
  stat_function(fun = dnorm, colour = "blue", args = list(mean = fem_mean, sd = sqrt(alt_var))) + ggtitle("Alternative hypothesis plot")

grid.arrange(null_plot,alternative_plot, ncol = 2, nrow = 1)
```

And here, again, we see a skewed distribution.

### Summary

In this report we've reviews the results of the mixture model vs pure type model. For each data file the results of the llrt were presented in table for ease of comparison between the log-normal and normal model. In addition some post-hoc analysis was done to understand the distribution structure of high llrt (strong mixture) features. 

We begin with noting that for all three files we can claim that there is a 
string evidence in favor of the mixture model hypothesis, reflected by the high number of rejected llrt.

In addition we can see that there isn't a strong pattern favoring the normal or log normal model, which might suggest that some features follow one distribution while the others follow the second.

We summarize by indicating that the features that had the highest llrt are the ones expected by the KLD schema. 
