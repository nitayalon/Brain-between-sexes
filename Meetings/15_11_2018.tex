\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{hyperref}
\usepackage[english]{babel}
\usepackage{enumitem,amssymb}
\usepackage{bbm}
% \usepackage{tikz}
\usepackage[usenames, dvipsnames]{color}
\newtheorem{remark}{Remark} 
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\newlist{todolist}{itemize}{2}
\setlist[todolist]{label=$\square$}

\newcommand{\tocomplete}{[To be completed]}

\newcommand{\addcomment}[1]{\textcolor{red}{#1}}

\newcommand{\addanswer}[1]{\textcolor{OliveGreen}{#1}}


\title{15/11/2018 meeting}
\author{Nitay Alon}

\begin{document}
\maketitle

\section{UK Biobank data}
\subsection*{Relevant data}
The relevant data for our analysis is found the following table:
	\begin{center}
		\begin{tabular}{|c|c|c|}
			\hline
			Data set name & Relevant Columns & Comments\\
			FA & 44-91 & Mean \\
			FA & 140-166 & \\
			\hline
			MD & 92-139 & Mean \\
			MD & 176-193 & \\
			\hline
			Volume & 194-332 & \\
			\hline
		\end{tabular}
	\end{center}
Noting that some features are normalized to brain size while other aren't.
The diagnostic columns are not part of the analysis for now.
\subsection*{Data processing}
We've decided on the following data processing schema:
	\begin{enumerate}
		\item Remove missing data
		\item Histogram of age for the remaining data
		\item Histogram of race for the remaining data
		\item KS test for log-normal /normal data
		\item Apply log transformation over the data, add the distance between 0 and the closest value $x_{(2)}$ if needed
		\item Normalize the data (standardization)
	\end{enumerate}
\subsection*{Data analysis}
To test our main hypothesis we apply the following routine:
	\begin{enumerate}
		\item Test the null hypothesis of single human distribution vs the composite mixture model
		\item If the null hypothesis is rejected test the null hypothesis of pure types vs the composite mixture model
		\item After the analysis is done, repeat the process with normalized for brain size data		
	\end{enumerate}
Enable testing over race - that is, repeat the process for each race separately.
\subsection*{Fitting the log normal model}
Following Isaco's comment on the relation between the variance and the distance between the minimum and maximum observation of log normal data:
If 
\[
\mathbf{X} = \exp{\mu + z \sigma} \implies \sigma^2 = log(\dfrac{E(X^2)}{E(X)^2})
\]
and
\[
\frac{max(X)}{min(X)} \sim \exp{\sigma \sqrt{8n}}
\]
now, if the distance between $|mu_1 - mu_2| < \frac{\sigma}{2}$ then the total std exceeded the within std by now more than 3\%. The proof is done using the binomial distribution of the between variable - $p(1-p)(\mu_1 - \mu_2)^2 < \frac{\sigma}{16}$
Apply the following procedure over the data to determine if we need to shift the distribution prior to log transformation
	\begin{enumerate}
		\item Select feature with relative high minimum observation
		\item Apply log transformation
		\item Plot histogram
		\item Remove $\frac{9}{10}$ of the distance to zero
		\item Repeat 2-3
		\item See if the transformed distribution yield "normaler" distribution
	\end{enumerate}


\subsection*{Reporting}
For each brain feature we report the following:
	\begin{enumerate}
		\item sd of the population, men and women (as part of testing the single distribution hypothesis) and as validation for the log transformation
		\item \textit{T-test} and Cohen's-d for mean distance
		\item After the EM is done - the mixture parameters
		\item Plot the empirical histogram and the densities 
	\end{enumerate}
In the end report (web app) enable the user to select either log normal or normal distribution for analysis.
\end{document} 